{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abe061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers.py loaded successfully.\n",
      "Number of files in file_paths: 115\n",
      "--- 1. Loading and Initial Downsampling (W=300, C_PATCH=128) ---\n",
      "Total Channels in file: 13752\n",
      "Downsampled Channels (C_TOTAL_DOWNSAMPLED): 3438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a69b576cdda466b8ef9fa3764d4b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Files:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape (Time, Dist): (718750, 3438)\n",
      "\n",
      "--- 2. Normalization ---\n",
      "\n",
      "--- 3. Graph Construction ---\n",
      "Graph Nodes (Channels in Patch): 128\n",
      "Adjacency Matrix Shape: (128, 128)\n",
      "Note: This matrix represents the spatial structure (Graph) for the GNN.\n",
      "\n",
      "--- 4. Patch Extraction and Train/Test Split ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f2ed4cd34346839cf893f8998c3393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patching:   0%|          | 0/4790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patches Created: 4790\n",
      "X_train (Normal Data for Training) Shape: (3832, 300, 128, 1)\n",
      "X_test (Test Data for Evaluation) Shape: (958, 300, 128, 1)\n",
      "Stored 'X_train' (ndarray)\n",
      "Stored 'X_test' (ndarray)\n",
      "Stored 'ADJACENCY_MATRIX' (ndarray)\n",
      "Stored 'W_TIME' (int)\n",
      "Stored 'C_PATCH' (int)\n",
      "Stored 'FILE_MAP_TEST' (ndarray)\n",
      "Stored 'C_TOTAL_DOWNSAMPLED' (int)\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration and Imports ---\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from Helpers import extract_metadata # Uncomment if available\n",
    "\n",
    "# --- Project Parameters ---\n",
    "directory = \"data/GC_data\" \n",
    "file_paths = sorted(glob.glob(os.path.join(directory, '*.hdf5')))\n",
    "print(f\"Number of files in file_paths: {len(file_paths)}\")\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "W_TIME = 300            # Time window size (steps)\n",
    "C_PATCH = 128           # Final number of channels in a patch (adjusts based on data)\n",
    "S_STRIDE = 150          # Time stride for patching (50% overlap)\n",
    "CHANNEL_STEP = 4        # Requested spatial downsampling (sampling every second channel)\n",
    "GRAPH_THRESHOLD_D = 3   # Index-based neighbor threshold d\n",
    "\n",
    "# Split ratio (Train: 80% Normal, Test: 20% Normal + Anomaly)\n",
    "TRAIN_RATIO = 0.8\n",
    "SIMULATED_ANOMALY_THRESHOLD = 0.8 # Used for simulated labels\n",
    "\n",
    "# --- 1. DATA LOADING AND INITIAL DOWNSAMPLING ---\n",
    "\n",
    "print(f\"--- 1. Loading and Initial Downsampling (W={W_TIME}, C_PATCH={C_PATCH}) ---\")\n",
    "\n",
    "all_data = []\n",
    "# Tracks the origin of each 10s data block (file name and start time)\n",
    "file_metadata = []\n",
    "\n",
    "# Get the initial metadata from the first file\n",
    "start_time, dt, dx, channels_raw, num_samples_raw = extract_metadata(file_paths[0])\n",
    "fs = 1/dt\n",
    "distance_array_m = channels_raw * dx\n",
    "distance_array_km = distance_array_m / 1000\n",
    "\n",
    "# Masking logic (keep channels up to 30km, which is all of the 15.9km cable)\n",
    "dmin_km, dmax_km = 0, 30 \n",
    "dist_mask = (distance_array_km >= dmin_km) & (distance_array_km <= dmax_km)\n",
    "\n",
    "# Downsample the channels that are within the mask\n",
    "downsampled_channels = channels_raw[dist_mask][::CHANNEL_STEP]\n",
    "C_TOTAL_DOWNSAMPLED = len(downsampled_channels)\n",
    "\n",
    "print(f\"Total Channels in file: {len(channels_raw)}\")\n",
    "print(f\"Downsampled Channels (C_TOTAL_DOWNSAMPLED): {C_TOTAL_DOWNSAMPLED}\")\n",
    "\n",
    "for file_idx, file_path in enumerate(tqdm(file_paths, desc=\"Loading Files\")):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = f['data'][:] # Load all data (Time, Channels)\n",
    "            \n",
    "            # Apply distance mask and downsampling\n",
    "            data = data[:, dist_mask][::1, ::CHANNEL_STEP] # Time downsampling (::1) is not applied here, only spatial\n",
    "            \n",
    "            # Store the data and metadata\n",
    "            all_data.append(data)\n",
    "            file_metadata.append({\n",
    "                'file_idx': file_idx,\n",
    "                'file_name': os.path.basename(file_path),\n",
    "                'start_time': extract_metadata(file_path)[0],\n",
    "                'time_steps': data.shape[0]\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError loading {file_path}. Skipping. Error: {e}\")\n",
    "\n",
    "combined_data = np.vstack(all_data)\n",
    "print(f\"Combined Data Shape (Time, Dist): {combined_data.shape}\")\n",
    "\n",
    "# --- 2. NORMALIZATION ---\n",
    "print(\"\\n--- 2. Normalization ---\")\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(combined_data.astype(np.float32).ravel().reshape(-1, 1)).reshape(combined_data.shape)\n",
    "\n",
    "# --- 3. GRAPH CONSTRUCTION ---\n",
    "print(\"\\n--- 3. Graph Construction ---\")\n",
    "\n",
    "def build_index_based_adj(num_nodes, d_threshold):\n",
    "    \"\"\"Creates a sparse Adjacency Matrix based on index proximity (single row).\"\"\"\n",
    "    adj = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            # Connect if index difference is <= d_threshold\n",
    "            if 0 < abs(i - j) <= d_threshold:\n",
    "                # Weight is inverse of distance (index difference) + epsilon\n",
    "                adj[i, j] = 1.0 / (abs(i - j) + 1e-6) \n",
    "    \n",
    "    # Normalize Adjacency Matrix (A_hat = D_inv * A_tilde, where A_tilde = A + I)\n",
    "    A_tilde = adj + np.eye(num_nodes, dtype=np.float32)\n",
    "    D = np.sum(A_tilde, axis=1)\n",
    "    D_inv = np.diag(1.0 / D)\n",
    "    A_hat = D_inv @ A_tilde\n",
    "    return A_hat.astype(np.float32)\n",
    "\n",
    "# Build the GNN adjacency matrix\n",
    "ADJACENCY_MATRIX = build_index_based_adj(C_PATCH, GRAPH_THRESHOLD_D)\n",
    "print(f\"Graph Nodes (Channels in Patch): {C_PATCH}\")\n",
    "print(f\"Adjacency Matrix Shape: {ADJACENCY_MATRIX.shape}\")\n",
    "print(f\"Note: This matrix represents the spatial structure (Graph) for the GNN.\")\n",
    "\n",
    "# --- 4. PATCH EXTRACTION AND TRAIN/TEST SPLIT ---\n",
    "print(\"\\n--- 4. Patch Extraction and Train/Test Split ---\")\n",
    "\n",
    "# Determine number of channels to keep in the patch for the GNN input\n",
    "# The paper used 310 channels total, which means 155 nodes per row. \n",
    "# Since we have 7812 nodes, we'll try to find the largest divisible size, \n",
    "# and for simplicity in the 2D CNN part of the U-Net, we'll slice a C_PATCH area.\n",
    "if C_TOTAL_DOWNSAMPLED < C_PATCH:\n",
    "    print(f\"Warning: Channel count {C_TOTAL_DOWNSAMPLED} is less than C_PATCH {C_PATCH}. Adjusting C_PATCH.\")\n",
    "    C_PATCH = C_TOTAL_DOWNSAMPLED\n",
    "\n",
    "def create_patches_and_track(data_matrix, time_window, dist_window, stride, file_metadata):\n",
    "    patches = []\n",
    "    file_map = [] # To store (file_idx, patch_start_time_step)\n",
    "    \n",
    "    time_steps, dist_channels = data_matrix.shape\n",
    "    \n",
    "    # Since we are not using spatial overlap across the full 7812 channels, \n",
    "    # we take a single, central slice of the downsampled channels (C_PATCH=128)\n",
    "    d_start = (dist_channels - dist_window) // 2 \n",
    "    d_end = d_start + dist_window\n",
    "    \n",
    "    # Track the cumulative time steps to link patches back to files\n",
    "    cumulative_time = 0\n",
    "    file_map_index = 0\n",
    "\n",
    "    for t in tqdm(range(0, time_steps - time_window + 1, stride), desc=\"Patching\"):\n",
    "        patch = data_matrix[t:t + time_window, d_start:d_end]\n",
    "        \n",
    "        if patch.shape == (time_window, dist_window):\n",
    "            patches.append(patch)\n",
    "            \n",
    "            # Find which original HDF5 file this time step belongs to\n",
    "            while file_map_index < len(file_metadata) - 1 and \\\n",
    "                  t + time_window > cumulative_time + file_metadata[file_map_index]['time_steps']:\n",
    "                cumulative_time += file_metadata[file_map_index]['time_steps']\n",
    "                file_map_index += 1\n",
    "            \n",
    "            # Store the file index and the start time step relative to the full dataset\n",
    "            file_map.append({\n",
    "                'file_idx': file_metadata[file_map_index]['file_idx'],\n",
    "                'file_name': file_metadata[file_map_index]['file_name'],\n",
    "                'time_start_step': t\n",
    "            })\n",
    "\n",
    "    return np.array(patches), np.array(file_map)\n",
    "\n",
    "\n",
    "# --- Apply Patching ---\n",
    "X_all_raw, FILE_MAP = create_patches_and_track(\n",
    "    normalized_data, W_TIME, C_PATCH, S_STRIDE, file_metadata\n",
    ")\n",
    "\n",
    "# Reshape for CNN/GNN input (batch_size, time_window, dist_channels_patch, 1)\n",
    "X_all = X_all_raw[..., np.newaxis]\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "N_PATCHES = X_all.shape[0]\n",
    "N_TRAIN = int(N_PATCHES * TRAIN_RATIO)\n",
    "\n",
    "X_train = X_all[:N_TRAIN]\n",
    "X_test = X_all[N_TRAIN:]\n",
    "\n",
    "X_test_raw = X_all_raw[N_TRAIN:] # For simulated labeling\n",
    "\n",
    "FILE_MAP_TEST = FILE_MAP[N_TRAIN:]\n",
    "\n",
    "print(f\"Total Patches Created: {N_PATCHES}\")\n",
    "print(f\"X_train (Normal Data for Training) Shape: {X_train.shape}\")\n",
    "print(f\"X_test (Test Data for Evaluation) Shape: {X_test.shape}\")\n",
    "\n",
    "# --- Store variables for the next step ---\n",
    "%store X_train X_test ADJACENCY_MATRIX W_TIME C_PATCH FILE_MAP_TEST C_TOTAL_DOWNSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54dedd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GraphDiffusion_DDPM\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " time_step_input (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " X0_input (InputLayer)          [(None, 300, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['time_step_input[0][0]']        \n",
      "                                                                                                  \n",
      " gcn_1 (GraphConvLayer)         (None, 300, 128, 1)  16384       ['X0_input[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 300)          600         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_2 (GraphConvLayer)         (None, 300, 128, 1)  16384       ['gcn_1[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 300, 1, 1)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 300, 128, 1)  0           ['gcn_2[0][0]',                  \n",
      "                                                                  'X0_input[0][0]']               \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (None, 300, 128, 1)  0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " unet_pre_concat (Concatenate)  (None, 300, 128, 3)  0           ['X0_input[0][0]',               \n",
      "                                                                  'add[0][0]',                    \n",
      "                                                                  'tf.tile[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 300, 128, 32  896         ['unet_pre_concat[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 150, 64, 32)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 150, 64, 64)  18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 75, 32, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 75, 32, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 75, 32, 128)  147584      ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 150, 64, 128  0           ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 150, 64, 192  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 150, 64, 64)  110656      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 300, 128, 64  0          ['conv2d_4[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 300, 128, 96  0           ['up_sampling2d_1[0][0]',        \n",
      "                                )                                 'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 300, 128, 32  27680       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " noise_output (Conv2D)          (None, 300, 128, 1)  33          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 412,569\n",
      "Trainable params: 412,569\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Stored 'model' (Functional)\n",
      "Stored 'ADJACENCY_MATRIX' (ndarray)\n",
      "Stored 'W_TIME' (int)\n",
      "Stored 'C_PATCH' (int)\n"
     ]
    }
   ],
   "source": [
    "# --- Imports and Variable Load ---\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%store -r X_train X_test ADJACENCY_MATRIX W_TIME C_PATCH FILE_MAP_TEST C_TOTAL_DOWNSAMPLED\n",
    "\n",
    "# --- GNN Components (Custom Layers) ---\n",
    "\n",
    "class GraphConvLayer(Layer):\n",
    "    \"\"\"\n",
    "    Implements the core Graph Convolution operation: X' = A_hat * X * W.\n",
    "    A_hat is the pre-calculated normalized adjacency matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, activation='relu', adj_matrix=None, **kwargs):\n",
    "        super(GraphConvLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = tf.keras.layers.Activation(activation)\n",
    "        \n",
    "        # FIX 1: Store the adjacency matrix as a non-trainable constant/weight.\n",
    "        if adj_matrix is None:\n",
    "            raise ValueError(\"Adjacency matrix must be provided to GraphConvLayer.\")\n",
    "        # Ensure it's a Tensor constant\n",
    "        self.adj_matrix_tensor = tf.constant(adj_matrix, dtype=tf.float32)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Input shape: (Batch, W_TIME, C_PATCH, 1) \n",
    "        C_IN = input_shape[2] \n",
    "        \n",
    "        # Check for matrix dimension consistency\n",
    "        if C_IN != self.adj_matrix_tensor.shape[0]:\n",
    "            raise ValueError(\n",
    "                f\"Input channel dimension ({C_IN}) must match Adjacency Matrix dimension ({self.adj_matrix_tensor.shape[0]}).\"\n",
    "            )\n",
    "\n",
    "        # Kernel shape: (C_PATCH, output_dim) -> [128, 128]\n",
    "        self.kernel = self.add_weight(shape=(C_IN, self.output_dim), \n",
    "                                      initializer='glorot_uniform',\n",
    "                                      name='kernel')\n",
    "        super(GraphConvLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # 1. Prepare inputs \n",
    "        X_in = tf.squeeze(inputs, axis=-1) # [?, 300, 128]\n",
    "\n",
    "        # 2. Transpose X to [Batch, C_PATCH, W_TIME] for Graph Convolution (A * X)\n",
    "        X_transposed = tf.transpose(X_in, perm=[0, 2, 1]) # [?, 128, 300]\n",
    "\n",
    "        # 3. Graph Convolution: A_hat * X_transposed\n",
    "        # Ax shape: [?, 128, 300]\n",
    "        Ax = tf.matmul(self.adj_matrix_tensor, X_transposed)\n",
    "\n",
    "        # 4. Transpose back: [Batch, W_TIME, C_PATCH]\n",
    "        Ax_transposed = tf.transpose(Ax, perm=[0, 2, 1]) # [?, 300, 128]\n",
    "        \n",
    "        # 5. Apply weight matrix W (the linear projection on nodes/channels)\n",
    "        output = tf.matmul(Ax_transposed, self.kernel) # [?, 300, 128]\n",
    "        \n",
    "        # 6. Apply Activation\n",
    "        output = self.activation(output)\n",
    "        \n",
    "        # 7. Add channel dimension back: [?, 300, 128, 1]\n",
    "        output = tf.expand_dims(output, axis=-1)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        # Note: Serializing the full matrix is complex; for notebook use, this is sufficient\n",
    "        config.update({\"output_dim\": self.output_dim})\n",
    "        return config\n",
    "\n",
    "# --- Full GraphDiffusion Model ---\n",
    "\n",
    "def build_graph_diffusion(input_shape,beta_min=1e-4, beta_max=0.02):\n",
    "    \"\"\"\n",
    "    Builds the GraphDiffusion model combining a GNN and a conditional U-Net.\n",
    "    \"\"\"\n",
    "    T_TIME, C_DIST, CHANNELS = input_shape\n",
    "    \n",
    "    # 1. INPUTS\n",
    "    X0_input = Input(shape=input_shape, name='X0_input')\n",
    "    time_step_input = Input(shape=(1,), dtype=tf.int32, name='time_step_input')\n",
    "\n",
    "    # 2. GNN (Spatial Representation Learning) - Figure 3\n",
    "    # GNN processes the clean input X0 to get spatial embedding H\n",
    "    # Note: We use C_PATCH as the output dim for the first GCN layer for the skip connection (H=S+X0).\n",
    "    # FIX: Pass the ADJACENCY_MATRIX tensor to the layer initialization.\n",
    "    gnn_out = GraphConvLayer(C_PATCH, activation='relu', adj_matrix=ADJACENCY_MATRIX, name='gcn_1')(X0_input)\n",
    "    S_spatial_features = GraphConvLayer(C_PATCH, activation='relu', adj_matrix=ADJACENCY_MATRIX, name='gcn_2')(gnn_out)\n",
    "    \n",
    "    # Spatial Embedding H = S + X0 (Element-wise Sum - residual connection)\n",
    "    H_spatial_embedding = layers.Add()([S_spatial_features, X0_input])\n",
    "\n",
    "    # 3. DDPM (Simulating the Diffusion Process in the Denoising Network)\n",
    "    # The actual DDPM forward process (X_t = sqrt(a_bar)X0 + sqrt(1-a_bar)epsilon)\n",
    "    # happens outside the model during the training loop.\n",
    "    \n",
    "    # Time Step Conditioning (Sinusoidal Positional Embedding)\n",
    "    time_emb = layers.Lambda(lambda x: tf.cast(x, tf.float32) / 1000)(time_step_input)\n",
    "    time_emb = layers.Dense(T_TIME, activation='relu')(time_emb)\n",
    "    \n",
    "    # Broadcast time embedding to match the spatial embedding shape (B, T, C, 1)\n",
    "    time_emb_bcast = layers.Reshape((T_TIME, 1, 1))(time_emb)\n",
    "    time_emb_bcast = tf.tile(time_emb_bcast, [1, 1, C_DIST, 1])\n",
    "\n",
    "    # DDPM INPUT (X_t is substituted by X0_input here, as the model learns to predict noise \n",
    "    # based on the noise level implicit in time_step_input)\n",
    "    \n",
    "    # Conditional Denoising U-Net Input (Concat X_t, H, and time_emb_bcast) - Figure 2\n",
    "    # In a proper DDPM implementation, X_t is the noisy input. Here, we use the original \n",
    "    # X0_input as a placeholder for the noisy input passed during training.\n",
    "    unet_input = layers.Concatenate(axis=-1, name='unet_pre_concat')([\n",
    "        X0_input, H_spatial_embedding, time_emb_bcast\n",
    "    ])\n",
    "    \n",
    "    # --- Denoising U-Net (Approximation of Figure 5 structure) ---\n",
    "    \n",
    "    # ENCODER (Downsampling)\n",
    "    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(unet_input)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1) # 150x64x64\n",
    "    \n",
    "    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2) # 75x32x128\n",
    "    \n",
    "    # BOTTLENECK\n",
    "    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn)\n",
    "\n",
    "    # DECODER (Upsampling + Skip Connections)\n",
    "    u1 = layers.UpSampling2D((2, 2))(bn) # 75x32x256\n",
    "    u1 = layers.Concatenate()([u1, c2])  # Skip connection from c2\n",
    "    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    \n",
    "    u2 = layers.UpSampling2D((2, 2))(c3) # 150x64x128\n",
    "    u2 = layers.Concatenate()([u2, c1])  # Skip connection from c1\n",
    "    c4 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u2)\n",
    "    \n",
    "    # Output - predicting the noise (epsilon)\n",
    "    # Output shape must match input shape (B, 300, 128, 1)\n",
    "    output_noise_pred = layers.Conv2D(CHANNELS, (1, 1), activation='linear', padding='same', name='noise_output')(c4)\n",
    "\n",
    "    # 4. Final Model\n",
    "    return Model(inputs=[X0_input, time_step_input], outputs=output_noise_pred, name='GraphDiffusion_DDPM')\n",
    "\n",
    "# --- Instantiate and Compile ---\n",
    "model = build_graph_diffusion(X_train.shape[1:], ADJACENCY_MATRIX.shape)\n",
    "model.summary()\n",
    "\n",
    "# NOTE: The actual training loop needs to implement the DDPM logic \n",
    "# (noise corruption and loss calculation) which is too complex for a standard \n",
    "# Keras compile/fit. We'll implement a custom training loop in the next cell.\n",
    "# The model's outputs are the predicted noise epsilon_theta(X_t, t, H).\n",
    "%store model ADJACENCY_MATRIX W_TIME C_PATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b6c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias X_test_raw\n",
      "no stored variable or alias model\n",
      "\n",
      "--- Training the GraphDiffusion Model on Normal Data (Unsupervised) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ba026740884ca2954f1ca168bf3538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.108157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c9d09d0c67409b9e8d89ac742b4649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Average Loss: 0.033939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cde5bc1fc524bdd9527d7ea3b38d16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Average Loss: 0.023035\n",
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Load all necessary components from previous steps\n",
    "%store -r X_train X_test X_test_raw FILE_MAP_TEST model W_TIME C_PATCH\n",
    "\n",
    "# --- DDPM Parameters and Functions ---\n",
    "T_STEPS = 25 # DDPM Total Timesteps\n",
    "BETA_MIN = 1e-4\n",
    "BETA_MAX = 0.02\n",
    "BATCH_SIZE = 8 \n",
    "EPOCHS = 3\n",
    "PERCENTILE = 99.9 # Tunable threshold, as discussed\n",
    "\n",
    "# Linear noise schedule\n",
    "betas = np.linspace(BETA_MIN, BETA_MAX, T_STEPS, dtype=np.float32)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = np.cumprod(alphas)\n",
    "\n",
    "# Tensor versions for fast computation\n",
    "alphas_cumprod_tf = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def forward_diffusion(X0, t):\n",
    "    \"\"\"\n",
    "    Applies noise to the clean signal X0 at time step t (Equation 8).\n",
    "    X_t = sqrt(alpha_bar_t) * X0 + sqrt(1 - alpha_bar_t) * epsilon\n",
    "    \"\"\"\n",
    "    # Select alpha_bar for the current batch's time steps t\n",
    "    alpha_bar_t = tf.gather(alphas_cumprod_tf, t)\n",
    "    alpha_bar_t = tf.reshape(alpha_bar_t, [-1, 1, 1, 1])\n",
    "\n",
    "    # Calculate required coefficients\n",
    "    sqrt_alpha_bar_t = tf.sqrt(alpha_bar_t)\n",
    "    sqrt_one_minus_alpha_bar_t = tf.sqrt(1.0 - alpha_bar_t)\n",
    "\n",
    "    # Generate random noise\n",
    "    epsilon = tf.random.normal(tf.shape(X0), dtype=tf.float32)\n",
    "    \n",
    "    # Compute X_t\n",
    "    Xt = sqrt_alpha_bar_t * X0 + sqrt_one_minus_alpha_bar_t * epsilon\n",
    "    return Xt, epsilon\n",
    "\n",
    "# --- Custom Training Step (Implements L_dif in Equation 9) ---\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss_metric = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "\n",
    "@tf.function\n",
    "def train_step(X0_batch):\n",
    "    # 1. Sample time step t uniformly\n",
    "    t = tf.random.uniform(shape=[tf.shape(X0_batch)[0]], minval=0, maxval=T_STEPS, dtype=tf.int32)\n",
    "    \n",
    "    # 2. Apply forward diffusion to get X_t and true noise epsilon\n",
    "    Xt, epsilon = forward_diffusion(X0_batch, t)\n",
    "    \n",
    "    # The GNN component requires a clean signal (X0) to create the spatial embedding H.\n",
    "    # The UNet component requires the noisy signal (Xt) to predict the noise.\n",
    "    \n",
    "    # We pass [Noisy_Xt, Time_t] to the model, and the model's internal GNN uses Xt \n",
    "    # as the nearest proxy for the clean signal X0 (a common GNN simplification).\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Predicted noise: epsilon_theta(X_t, t, H(X0))\n",
    "        predicted_noise = model([Xt, t], training=True) \n",
    "\n",
    "        # Calculate L2 loss (MSE) on the noise prediction (Equation 9)\n",
    "        loss = tf.keras.losses.mean_squared_error(epsilon, predicted_noise)\n",
    "        \n",
    "    # Apply gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Update loss tracker\n",
    "    loss_metric.update_state(loss)\n",
    "    return loss\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"\\n--- Training the GraphDiffusion Model on Normal Data (Unsupervised) ---\")\n",
    "X_train_ds = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size=1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_metric.reset_states()\n",
    "    \n",
    "    for X0_batch in tqdm(X_train_ds, desc=f\"Epoch {epoch + 1}/{EPOCHS}\"):\n",
    "        train_step(X0_batch)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {loss_metric.result().numpy():.6f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d9cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference and Anomaly Score Calculation ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Inference and Anomaly Score Calculation ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate scores and reconstructions for Test data\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m test_error, X_test_pred \u001b[38;5;241m=\u001b[39m calculate_anomaly_scores(\u001b[43mX_test\u001b[49m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 4. Evaluation Metrics (Focus on Anomaly Score)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m anomaly_threshold \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(calculate_anomaly_scores(X_train)[\u001b[38;5;241m0\u001b[39m], PERCENTILE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_anomaly_scores(X_data):\n",
    "    \"\"\"\n",
    "    Calculates the reconstruction error (Anomaly Score) using a simplified DDPM reverse pass.\n",
    "    We predict the noise and reconstruct X0_pred (Equation 10 derivation).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the median timestep t_mid for robust reconstruction\n",
    "    t_mid = T_STEPS // 2\n",
    "    t_mid_batch = tf.ones(tf.shape(X_data)[0], dtype=tf.int32) * t_mid\n",
    "    \n",
    "    # 1. Apply forward diffusion to get the noisy input X_t\n",
    "    Xt_mid, _ = forward_diffusion(X_data, t_mid_batch)\n",
    "    \n",
    "    # 2. Predict the noise from the noisy input Xt_mid\n",
    "    predicted_noise = model([Xt_mid, t_mid_batch], training=False) \n",
    "    \n",
    "    # 3. Simplified X0 reconstruction (rearrange forward_diffusion formula):\n",
    "    # X0_pred = (Xt_mid - sqrt(1-alpha_bar)*epsilon_theta) / sqrt(alpha_bar)\n",
    "    alpha_bar_mid = alphas_cumprod[t_mid]\n",
    "    sqrt_alpha_bar_mid = np.sqrt(alpha_bar_mid)\n",
    "    sqrt_one_minus_alpha_bar_mid = np.sqrt(1.0 - alpha_bar_mid)\n",
    "    \n",
    "    X0_pred = (Xt_mid - sqrt_one_minus_alpha_bar_mid * predicted_noise) / sqrt_alpha_bar_mid\n",
    "    \n",
    "    # Anomaly Score (MSE/L2 error) - Equation 11\n",
    "    error = tf.reduce_mean(tf.square(X_data - X0_pred), axis=[1, 2, 3]).numpy()\n",
    "    return error, X0_pred.numpy()\n",
    "\n",
    "print(\"\\n--- Inference and Anomaly Score Calculation ---\")\n",
    "\n",
    "# Calculate scores and reconstructions for Test data\n",
    "test_error, X_test_pred = calculate_anomaly_scores(X_test)\n",
    "\n",
    "# 4. Evaluation Metrics (Focus on Anomaly Score)\n",
    "anomaly_threshold = np.percentile(calculate_anomaly_scores(X_train)[0], PERCENTILE)\n",
    "\n",
    "print(f\"\\n--- UNSUPERVISED ANOMALY SCORE METRICS ---\")\n",
    "print(f\"Anomaly Threshold (Top {100-PERCENTILE}%) : {anomaly_threshold:.6f}\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# 5. Identify Top Anomalous Files (New Evaluation Goal)\n",
    "print(\"\\n--- Identifying Top 5 Anomalous Files (Actionable Insight) ---\")\n",
    "\n",
    "# Aggregate by file name and calculate average score\n",
    "file_scores = {}\n",
    "file_counts = {}\n",
    "for i, result in enumerate(test_error):\n",
    "    name = FILE_MAP_TEST[i]['file_name']\n",
    "    score = test_error[i]\n",
    "    file_scores[name] = file_scores.get(name, 0) + score\n",
    "    file_counts[name] = file_counts.get(name, 0) + 1\n",
    "\n",
    "# Calculate average score\n",
    "avg_file_scores = {name: file_scores[name] / file_counts[name] for name in file_scores}\n",
    "\n",
    "# Sort and get top 5\n",
    "top_files = sorted(avg_file_scores.items(), key=lambda item: item[1], reverse=True)[:5]\n",
    "\n",
    "print(\"\\nTop 5 Most Anomalous HDF5 Files (Highest Average Score):\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "for rank, (file_name, avg_score) in enumerate(top_files):\n",
    "    print(f\"Rank {rank+1}: {file_name} (Average Score: {avg_score:.6f})\")\n",
    "\n",
    "# 6. Visualize the Top 5 Anomalous Patches (Visual Inspection)\n",
    "print(\"\\n--- Visualizing the Top Anomalous Patches for Inspection ---\")\n",
    "\n",
    "# Find the indices of the top 5 highest scoring patches in the test set\n",
    "top_k_patches = np.argsort(test_error)[::-1][:5]\n",
    "\n",
    "# Use X_test_raw for visualization as it contains the NumPy version\n",
    "X_test_raw_np = X_test.squeeze()\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(12, 10))\n",
    "fig.suptitle('GraphDiffusion: Top 5 Anomalous Patches (Input vs. Reconstruction)', fontsize=14)\n",
    "\n",
    "for i, patch_idx in enumerate(top_k_patches):\n",
    "    # Use the NumPy version of the input and the reconstructed output\n",
    "    input_patch = X_test_raw_np[patch_idx]\n",
    "    reconstructed_patch = X_test_pred[patch_idx].squeeze()\n",
    "    \n",
    "    vmax = np.percentile(input_patch, 99.5)\n",
    "    \n",
    "    # Input\n",
    "    ax = axes[i, 0]\n",
    "    ax.imshow(input_patch, aspect='auto', cmap='jet', vmin=0, vmax=vmax)\n",
    "    ax.set_title(f\"Input (Score: {test_error[patch_idx]:.4f})\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Reconstruction\n",
    "    ax = axes[i, 1]\n",
    "    ax.imshow(reconstructed_patch, aspect='auto', cmap='jet', vmin=0, vmax=vmax)\n",
    "    ax.set_title(\"Reconstruction\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig('top_anomalous_patches.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
